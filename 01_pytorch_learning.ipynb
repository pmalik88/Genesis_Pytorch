{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reproducibility (trying to take random out of random)"
      ],
      "metadata": {
        "id": "KJ4Vak4VVinz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHob0DldVfBL",
        "outputId": "4e216934-fc4c-472c-9aa5-215f459a0224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8708, 0.4196, 0.1955, 0.2360],\n",
            "        [0.6267, 0.6481, 0.7624, 0.9207],\n",
            "        [0.7392, 0.3772, 0.1011, 0.0071]])\n",
            "tensor([[0.8774, 0.2265, 0.1448, 0.0155],\n",
            "        [0.1693, 0.9440, 0.1993, 0.0399],\n",
            "        [0.6766, 0.8035, 0.8440, 0.9679]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "random_tensor_A=torch.rand(3,4)\n",
        "random_tensor_B=torch.rand(3,4)\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A==random_tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Set the random seed\n",
        "Random_seed = 42\n",
        "torch.manual_seed(Random_seed)\n",
        "random_tensor_A=torch.rand(3,4)\n",
        "random_tensor_B=torch.rand(3,4)\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A==random_tensor_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Mop6IbecwSR",
        "outputId": "04ecc65a-57f8-4621-afa8-c47cf14bb81a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Set the random seed\n",
        "Random_seed = 42\n",
        "torch.manual_seed(Random_seed)\n",
        "random_tensor_A=torch.rand(3,4)\n",
        "torch.manual_seed(Random_seed)\n",
        "random_tensor_B=torch.rand(3,4)\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A==random_tensor_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPqtOb8CdVyb",
        "outputId": "88fdffca-4a25-45fc-8183-b30f80af9231"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Set the random seed\n",
        "torch.manual_seed(42)\n",
        "random_tensor_A=torch.rand(3,4)\n",
        "torch.manual_seed(42)\n",
        "random_tensor_B=torch.rand(3,4)\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A==random_tensor_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EMJnYoddkRA",
        "outputId": "7104fa32-48a6-47c6-f8a4-3a4b8f5d5b26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running tensors and Pytorch Objects on GPU for faster computations"
      ],
      "metadata": {
        "id": "CVVSSntZd33e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Getting a GPU use tim Dettmers\n",
        "# Use google colab, AWS,AZURE\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiCy_kbed2VR",
        "outputId": "08fe4e9a-92a7-4aeb-ea1a-fb3b0e1dde1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 23 09:40:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Check for GPU access for Pytorch\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzPDLzL0fFrQ",
        "outputId": "b38a9292-d595-4681-d2b0-f37cd8dab98d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up device agnostic code\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oIBVJC2Dfd2w",
        "outputId": "beda5eb5-5fad-4ee3-f999-f9ab77a826ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JgkxRwPgRIw",
        "outputId": "6b51d3db-83b0-49d6-95d3-9d044f646c24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Putting Tenosrs and models on GPU for faster computations\n",
        "tensor=torch.tensor([1,2,3])\n",
        "print(tensor,tensor.device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS9NS64tfun3",
        "outputId": "ec17a9a9-ae88-44cf-91f8-332fca657ffc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor on GPU\n",
        "tensor_on_gpu=tensor.to(device)\n",
        "print(tensor_on_gpu,tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4_65iHAgfsK",
        "outputId": "7aa7a871-41f8-433a-bf87-9ddd61ea352a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3], device='cuda:0') cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Move tensor back to CPU\n",
        "#If tensor on GPU , we can not transform it to Numpy\n",
        "# put Sensor back to CPU and then transorm to Numpy"
      ],
      "metadata": {
        "id": "Q78-OreohGnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu.numpy() # error"
      ],
      "metadata": {
        "id": "apo6WHaEg6SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_back_on_cpu=tensor_on_gpu.cpu().numpy()\n",
        "print(tensor_back_on_cpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R02jaAMVhPUQ",
        "outputId": "916faf19-e964-49e5-b4d7-d16489765d6e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excercises and **Extracurriculam**\n",
        "https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
      ],
      "metadata": {
        "id": "aF2btJiEiR8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OmvHZjkDh3Yl",
        "outputId": "336a2a6f-04a7-4bda-ff96-59c2ea59384d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}